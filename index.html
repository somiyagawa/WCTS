<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI-Powered Language Revitalization: A Case Study of Truku Seediq</title>
    <style>
        :root {
            --primary-color: #005b96;
            --secondary-color: #6497b1;
            --accent-color: #eb6e4b;
            --text-color: #333;
            --light-bg: #f8f9fa;
            --dark-bg: #011f4b;
            --highlight: #b3e5fc;
            --slide-transition: 0.6s;
        }
        
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }
        
        body {
            font-family: 'Segoe UI', 'Roboto', 'Helvetica Neue', Arial, sans-serif;
            color: var(--text-color);
            background-color: var(--light-bg);
            line-height: 1.6;
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            width: 100vw;
        }
        
        .slide-container {
            width: 100vw;
            height: 56.25vw; /* 16:9 aspect ratio */
            max-height: 100vh;
            position: relative;
            overflow: hidden;
            margin: 0 auto;
        }
        
        @media screen and (min-aspect-ratio: 16/9) {
            .slide-container {
                width: calc(100vh * 16/9);
                height: 100vh;
                margin: 0 auto;
            }
        }
        
        .slide {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            opacity: 0;
            transform: translateX(100%);
            transition: transform var(--slide-transition), opacity var(--slide-transition);
            overflow-y: auto;
            background-color: white;
            display: flex;
            flex-direction: column;
        }
        
        .slide.active {
            opacity: 1;
            transform: translateX(0);
            z-index: 1;
        }
        
        .slide.prev {
            transform: translateX(-100%);
        }
        
        .header {
            background-color: var(--primary-color);
            color: white;
            padding: 15px 40px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        
        .header h1 {
            font-size: 1.2rem;
            font-weight: 500;
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
        }
        
        .slide-number {
            font-size: 0.9rem;
            font-weight: 400;
        }
        
        .slide-content {
            flex: 1;
            padding: 40px;
            display: flex;
            max-width: 1400px;
            margin: 0 auto;
            width: 100%;
        }
        
        .title-slide .slide-content {
            justify-content: center;
            align-items: center;
            flex-direction: column;
            text-align: center;
            background-color: var(--dark-bg);
            color: white;
            height: 100%;
        }
        
        .full-width {
            width: 100%;
        }
        
        .two-column {
            display: flex;
            gap: 40px;
            width: 100%;
        }
        
        .slide-text {
            flex: 1;
        }
        
        .slide-image {
            width: 45%;
            display: flex;
            justify-content: center;
            align-items: center;
            background-color: var(--light-bg);
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 8px 30px rgba(0,0,0,0.12);
        }
        
        .slide-image img {
            max-width: 100%;
            max-height: 100%;
            object-fit: cover;
        }
        
        h2 {
            color: var(--primary-color);
            font-size: 2.2rem;
            margin-bottom: 25px;
            border-bottom: 2px solid var(--secondary-color);
            padding-bottom: 10px;
        }
        
        h3 {
            color: var(--secondary-color);
            font-size: 1.6rem;
            margin: 20px 0 15px;
        }
        
        p {
            margin-bottom: 15px;
            line-height: 1.7;
        }
        
        ul, ol {
            margin-left: 20px;
            margin-bottom: 15px;
        }
        
        li {
            margin-bottom: 10px;
        }
        
        .navigation {
            position: fixed;
            bottom: 40px;
            left: 0;
            right: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            gap: 15px;
            z-index: 100;
        }
        
        .nav-btn {
            padding: 12px 25px;
            background-color: var(--primary-color);
            color: white;
            border: none;
            border-radius: 30px;
            cursor: pointer;
            font-size: 16px;
            font-weight: 500;
            transition: all 0.3s ease;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            display: flex;
            align-items: center;
            gap: 8px;
        }
        
        .nav-btn:hover {
            background-color: var(--secondary-color);
            transform: translateY(-2px);
            box-shadow: 0 6px 8px rgba(0,0,0,0.15);
        }
        
        .nav-btn:active {
            transform: translateY(0);
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        .nav-btn:disabled {
            background-color: #ccc;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
        }
        
        .dots-container {
            display: flex;
            gap: 8px;
            margin: 0 10px;
        }
        
        .dot {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background-color: #ccc;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        
        .dot.active {
            background-color: var(--primary-color);
            transform: scale(1.2);
        }
        
        .content-box {
            background-color: var(--light-bg);
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 20px;
            border-left: 4px solid var(--primary-color);
            box-shadow: 0 2px 5px rgba(0,0,0,0.05);
        }
        
        .content-box h4 {
            color: var(--primary-color);
            margin-bottom: 10px;
            font-size: 1.2rem;
        }
        
        .highlight {
            color: var(--accent-color);
            font-weight: bold;
        }
        
        .title-slide h1 {
            font-size: 3.5rem;
            margin-bottom: 30px;
            text-shadow: 0 2px 4px rgba(0,0,0,0.2);
            animation: fadeInUp 1.5s ease;
        }
        
        .title-slide h2 {
            color: var(--secondary-color);
            font-size: 1.8rem;
            margin-bottom: 30px;
            border: none;
            animation: fadeInUp 1.8s ease;
        }
        
        .title-logo {
            margin-bottom: 50px;
            max-width: 200px;
            animation: fadeIn 2s ease;
        }
        
        .progress-bar {
            position: fixed;
            top: 0;
            left: 0;
            height: 3px;
            background-color: var(--accent-color);
            z-index: 1000;
            transition: width 0.3s ease;
        }
        
        .citation {
            font-size: 0.9rem;
            color: #666;
            font-style: italic;
            margin-top: 30px;
        }
        
        .ai-method {
            background-color: #f1f8fe;
            border: 1px solid #d0e6fb;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }
        
        .ai-method h4 {
            color: var(--primary-color);
            font-size: 1.2rem;
            margin-bottom: 10px;
        }
        
        .method-icon {
            display: inline-block;
            margin-right: 10px;
            width: 30px;
            height: 30px;
            text-align: center;
            line-height: 30px;
            background-color: var(--primary-color);
            color: white;
            border-radius: 50%;
            font-weight: bold;
        }
        
        .data-stat {
            background-color: var(--primary-color);
            color: white;
            padding: 30px;
            border-radius: 8px;
            margin: 20px 0;
            text-align: center;
        }
        
        .data-stat .number {
            font-size: 2.5rem;
            font-weight: bold;
            margin-bottom: 10px;
        }
        
        .data-stat .label {
            font-size: 1.1rem;
            opacity: 0.9;
        }
        
        .source-image {
            display: inline-block;
            width: 40px;
            height: 40px;
            margin-right: 15px;
            vertical-align: middle;
            background-color: var(--light-bg);
            border-radius: 5px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            overflow: hidden;
        }
        
        .source-image img {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        
        .ai-method h4 {
            display: flex;
            align-items: center;
        }
        
        .timeline {
            position: relative;
            padding-left: 30px;
            margin: 30px 0;
        }
        
        .timeline:before {
            content: "";
            position: absolute;
            left: 0;
            top: 0;
            bottom: 0;
            width: 2px;
            background-color: var(--secondary-color);
        }
        
        .timeline-item {
            position: relative;
            padding-bottom: 25px;
        }
        
        .timeline-item:before {
            content: "";
            position: absolute;
            left: -34px;
            top: 5px;
            width: 10px;
            height: 10px;
            border-radius: 50%;
            background-color: var(--accent-color);
            border: 3px solid white;
        }
        
        .timeline-item h4 {
            margin-bottom: 5px;
            color: var(--primary-color);
        }
        
        .timeline-date {
            font-size: 0.9rem;
            color: #666;
            margin-bottom: 5px;
        }
        
        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }
        
        @keyframes fadeInUp {
            from { 
                opacity: 0;
                transform: translateY(20px);
            }
            to { 
                opacity: 1;
                transform: translateY(0);
            }
        }
        
        .profile-image {
            width: 100%;
            aspect-ratio: 1;
            background-color: var(--light-bg);
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 8px 30px rgba(0,0,0,0.12);
            margin-bottom: 20px;
        }
        
        .profile-image img {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        
        .flow-diagram {
            width: 100%;
            margin: 20px 0;
            padding: 15px;
            background-color: white;
            border-radius: 8px;
            box-shadow: 0 2px 15px rgba(0,0,0,0.1);
        }
        
        .code-block {
            background-color: #2d2d2d;
            color: #e6e6e6;
            padding: 15px;
            border-radius: 5px;
            font-family: 'Courier New', Courier, monospace;
            font-size: 14px;
            line-height: 1.4;
            overflow-x: auto;
            margin: 10px 0;
        }
        
        .code-comment {
            color: #6a9955;
            font-style: italic;
        }
        
        .tech-pill {
            display: inline-block;
            padding: 4px 12px;
            background-color: var(--accent-color);
            color: white;
            border-radius: 20px;
            font-size: 0.8rem;
            margin-right: 8px;
            margin-bottom: 8px;
        }
        
        @media (max-width: 900px) {
            .two-column {
                flex-direction: column;
            }
            
            .slide-image {
                width: 100%;
                height: 300px;
                margin-bottom: 20px;
            }
            
            h2 {
                font-size: 1.8rem;
            }
            
            .header h1 {
                font-size: 1rem;
            }
        }
    </style>
</head>
<body>
    <div class="progress-bar" id="progressBar"></div>
    
    <div class="slide-container">
        <!-- Slide 1: Title -->
        <div class="slide title-slide active">
            <div class="slide-content">
                <img src="/api/placeholder/200/200" alt="FALCOHN Logo" class="title-logo" />
                <h1>AI-Powered Language Revitalization</h1>
                <h2>A Case Study of Truku Seediq</h2>
                <p>Field-based Approaches to Language, Cognition, and Human Nature (FALCOHN)</p>
            </div>
        </div>

        <!-- Slide 2: Introduction to Language Endangerment -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">2/19</div>
            </div>
            <div class="slide-content">
                <div class="two-column">
                    <div class="slide-text">
                        <h2>The Global Language Endangerment Crisis</h2>
                        
                        <div class="data-stat">
                            <div class="number">40-44%</div>
                            <div class="label">of world's ~7,000 languages endangered</div>
                        </div>
                        
                        <ul>
                            <li><strong>Rate of Loss:</strong> Approximately one language disappears every two weeks</li>
                            <li><strong>Significance:</strong> Each extinction represents loss of unique cultural heritage, knowledge systems, and intellectual diversity</li>
                        </ul>
                        
                        <h3>Taiwan's Context</h3>
                        <p>Taiwan is home to numerous endangered Austronesian languages affected by colonial legacies, Mandarin dominance, and socioeconomic pressures.</p>
                        
                        <div class="content-box">
                            <h4>Truku Seediq Status</h4>
                            <ul>
                                <li>Ethnic population: ~32,333</li>
                                <li>Fluent speakers: ~4,217 (2021 CIP data)</li>
                                <li>UNESCO Classification: <span class="highlight">Critically Endangered</span></li>
                                <li>Sharp decline in intergenerational transmission</li>
                            </ul>
                        </div>
                    </div>
                    <div class="slide-image">
                        <img src="/api/placeholder/650/500" alt="World map showing endangered language distribution" />
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 3: Truku Seediq Language Profile -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">3/19</div>
            </div>
            <div class="slide-content">
                <div class="full-width">
                    <h2>The Truku Seediq Language</h2>
                    
                    <h3>Linguistic Profile</h3>
                    <ul>
                        <li><strong>Classification:</strong> Atayalic branch of Austronesian family</li>
                        <li><strong>Phonology:</strong>
                            <ul>
                                <li>19 consonants, 4 vowels (/i/, /u/, /ə/, /a/)</li>
                                <li>Distinctive velar fricatives and uvular stops</li>
                                <li>Notable dorsal consonant harmony process</li>
                            </ul>
                        </li>
                        <li><strong>Morphology:</strong>
                            <ul>
                                <li>Complex affixation marking voice/focus system</li>
                                <li>Productive reduplication for pluralization and reciprocal forms</li>
                            </ul>
                        </li>
                        <li><strong>Syntax:</strong>
                            <ul>
                                <li>Predominant VOS word order with ergative alignment</li>
                                <li>Uses various "predicate extenders" for aspectual, modal, and adverbial meanings</li>
                            </ul>
                        </li>
                    </ul>
                    
                    <div class="content-box">
                        <h4>Current Community Initiatives</h4>
                        <p>The <strong>Taiwan Truku Cultural Promotion Association</strong> (est. 2021) leads revitalization efforts through community consensus-building, resource development, educational initiatives, and media production.</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 4: Research Team & Approach -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">4/19</div>
            </div>
            <div class="slide-content">
                <div class="full-width">
                    <h2>Research Framework: OS科研4 (2024-2027)</h2>
                    
                    <h3>OS科研 Project Series</h3>
                    <div class="timeline">
                        <div class="timeline-item">
                            <h4>OS科研1 (2010-2014)</h4>
                            <div class="timeline-date">Grant-in-Aid for Scientific Research (S)</div>
                            <p>"A field-based cognitive neuroscientific study of the processing of OS-type languages" - Focus on Kaqchikel Mayan</p>
                        </div>
                        
                        <div class="timeline-item">
                            <h4>OS科研2 (2015-2019)</h4>
                            <div class="timeline-date">Grant-in-Aid for Scientific Research (A)</div>
                            <p>"A field-based psycholinguistic study of the discourse processing mechanisms of OS languages" - Expanded to include Truku</p>
                        </div>
                        
                        <div class="timeline-item">
                            <h4>OS科研3 (2019-2024)</h4>
                            <div class="timeline-date">Grant-in-Aid for Scientific Research (S)</div>
                            <p>"Field-based Cognitive Neuroscientific Study of Word Order in Language and Order of Thinking from the OS Language Perspective"</p>
                        </div>
                        
                        <div class="timeline-item">
                            <h4>OS科研4 (2024-2027)</h4>
                            <div class="timeline-date">Grant-in-Aid for Scientific Research (A)</div>
                            <p>"Pseudo-Dynamic Preservation and Elucidation of Neural Processing of Endangered Languages Based on Natural Discourse Corpora with Physiological Indices"</p>
                        </div>
                    </div>
                    
                    <h3>Current Project</h3>
                    <p>OS科研4 builds on previous research by shifting focus toward:</p>
                    <ul>
                        <li>Creating physiologically-indexed natural discourse corpora for endangered languages</li>
                        <li>Developing AI dialogue systems for language preservation</li>
                        <li>Comparing OS-type languages (VOS languages like Truku and Kaqchikel) with SO-type languages</li>
                        <li>Investigating the relationship between language order and thought order</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Slide 5: Key Collaborator - Dr. Apay Ai-yu Tang -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">5/19</div>
            </div>
            <div class="slide-content">
                <div class="two-column">
                    <div class="slide-text">
                        <h2>Dr. Apay Ai-yu Tang</h2>
                        
                        <div class="content-box">
                            <h4>Indigenous Scholar & Language Specialist</h4>
                            <p>Dr. Apay Ai-yu Tang is a Truku Seediq scholar who has made significant contributions to the documentation, preservation, and revitalization of Indigenous languages in Taiwan.</p>
                        </div>
                        
                        <h3>Academic Background</h3>
                        <ul>
                            <li><strong>Ph.D. in Linguistics</strong> - University of Hawaiʻi at Mānoa (2011)</li>
                            <li><strong>Associate Professor</strong> - Department of Indigenous Language and Communication, National Dong Hwa University</li>
                            <li><strong>Faculty Affiliate</strong> - Center for International Indigenous Affairs (CIIA)</li>
                        </ul>
                        
                        <h3>Contributions to Truku Seediq Research</h3>
                        <ul>
                            <li><strong>Language Documentation</strong> - Extensive work documenting the Truku Seediq language structure and usage</li>
                            <li><strong>Psycholinguistic Assessment</strong> - Developed methodologies to assess language shift and proficiency</li>
                            <li><strong>Language Planning</strong> - Created remedial strategies for language revitalization</li>
                            <li><strong>Syntax Research</strong> - Co-authored studies on Seediq syntax and language processing</li>
                        </ul>
                        
                        <h3>Collaboration with FALCOHN</h3>
                        <ul>
                            <li>Provides critical cultural and linguistic expertise to ensure authentic representation of Truku language</li>
                            <li>Bridges academic research with community needs and values</li>
                            <li>Guides ethical approaches to language data collection and AI implementation</li>
                            <li>Evaluates effectiveness of language teaching methodologies</li>
                        </ul>
                    </div>
                    <div class="slide-image">
                        <div class="profile-image">
                            <img src="/api/placeholder/400/400" alt="Dr. Apay Ai-yu Tang" />
                        </div>
                        
                        <div class="content-box">
                            <h4>Specialized Expertise</h4>
                            <p>Dr. Tang's doctoral research "From diagnosis to remedial plan: A psycholinguistic assessment of language shift, proficiency, and language planning in Truku Seediq" (2011) established a framework that continues to inform the FALCOHN project's methodological approach.</p>
                        </div>
                        
                        <div class="content-box">
                            <h4>Community-Centered Approach</h4>
                            <p>Dr. Tang emphasizes grassroots initiatives and collaborative partnerships, believing that effective language revitalization must be driven by and for the community, with technology serving as a supportive tool.</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 6: Key Collaborator - Pastor Chang -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">6/19</div>
            </div>
            <div class="slide-content">
                <div class="two-column">
                    <div class="slide-text">
                        <h2>Pastor Chang</h2>
                        
                        <div class="content-box">
                            <h4>Community Elder & AI Avatar Model</h4>
                            <p>Pastor Chang is a key cultural resource person in the Truku community who serves as the primary model for the AI Avatar teacher in the Truku AI-driven revitalization project. He contributes significantly to language preservation through his extensive Bible translation work and audio-visual documentation efforts.</p>
                        </div>
                        
                        <h3>Contributions to Language Preservation</h3>
                        <ul>
                            <li><strong>Extensive Bible Translation</strong> - Has translated numerous books from both the New Testament (新約聖書) and Old Testament (旧約聖書) into Truku Seediq, creating a valuable corpus of language materials</li>
                            <li><strong>Digital Documentation</strong> - Records and uploads audio and text videos of Truku Bible translations to YouTube</li>
                            <li><strong>HeyGen AI Avatar Model</strong> - Serves as the primary model and voice for the AI teacher in the Truku AI-driven revitalization project</li>
                            <li><strong>Cultural Knowledge</strong> - Provides authentic cultural context essential for AI-powered language modeling</li>
                        </ul>
                        
                        <h3>Extensive Bible Translation Work</h3>
                        <p>Pastor Chang has translated numerous books from both the New Testament (新約聖書) and Old Testament (旧約聖書) into Truku Seediq, creating a valuable corpus of language materials. This extensive work includes major portions of Ephesians, Galatians, Colossians, Hebrews, Matthew, John, Revelation, Psalms, Genesis, and many others.</p>
                    </div>
                    <div class="slide-image">
                        <div class="profile-image">
                            <img src="/api/placeholder/400/400" alt="Pastor Chang" />
                        </div>
                        
                        <div class="content-box">
                            <h4>Digital Preservation Efforts</h4>
                            <p>Creates and uploads YouTube videos featuring Truku audio recordings synchronized with text, creating valuable linguistic resources for language learners and researchers.</p>
                        </div>
                        
                        <div class="content-box">
                            <h4>AI Teacher Avatar</h4>
                            <p>Pastor Chang's likeness, voice, and teaching style form the foundation of the primary AI Avatar teacher in the Truku AI-driven revitalization project. His cultural authority and natural teaching ability make him the ideal model for creating a virtual instructor that resonates with the community.</p>
                        </div>
                        
                        <div class="content-box">
                            <h4>Community Impact</h4>
                            <p>His work has helped establish a significant corpus of authentic, high-quality Truku language content that serves as valuable training data for AI language models while simultaneously providing learning materials for community members.</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 7: Introduction to AI for Language Revitalization -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">7/19</div>
            </div>
            <div class="slide-content">
                <div class="full-width">
                    <h2>AI Technologies for Language Revitalization</h2>
                    
                    <h3>How AI Can Address Language Endangerment</h3>
                    <ul>
                        <li><strong>Automated Documentation:</strong> Processing large volumes of language data efficiently</li>
                        <li><strong>Accessible Learning:</strong> Creating scalable, always-available learning resources</li>
                        <li><strong>Preservation of Endangered Knowledge:</strong> Capturing cultural contexts beyond just words</li>
                        <li><strong>Cross-Generational Transfer:</strong> Bridging the gap when intergenerational transmission is broken</li>
                    </ul>
                    
                    <div class="content-box">
                        <h4>Core AI Technologies in Our Project</h4>
                        <div style="display: flex; flex-wrap: wrap; gap: 10px; margin-top: 10px;">
                            <div class="tech-pill">Deep Learning</div>
                            <div class="tech-pill">Fine-Tuning</div>
                            <div class="tech-pill">Retrieval Augmented Generation</div>
                            <div class="tech-pill">Neural Machine Translation</div>
                            <div class="tech-pill">Speech Recognition</div>
                            <div class="tech-pill">Digital Avatars</div>
                        </div>
                    </div>
                    
                    <h3>Technology + Community Partnership</h3>
                    <p>Our approach integrates cutting-edge AI technologies with deep community engagement, ensuring that:</p>
                    <ul>
                        <li>Technologies serve community needs, not the reverse</li>
                        <li>Cultural knowledge and context remain under community control</li>
                        <li>Technological solutions complement rather than replace human interactions</li>
                        <li>Capacity building enables community members to develop and maintain their own digital tools</li>
                    </ul>
                    
                    <div class="content-box">
                        <h4>Ethical Framework</h4>
                        <p>Our project adheres to principles of data sovereignty, informed consent, community control, and reciprocal research relationships to ensure that AI technologies support rather than extract from the Truku community.</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 8: Deep Learning Fundamentals -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">8/19</div>
            </div>
            <div class="slide-content">
                <div class="two-column">
                    <div class="slide-text">
                        <h2>Deep Learning Fundamentals</h2>
                        
                        <h3>What is Deep Learning?</h3>
                        <p>Deep learning is a subset of machine learning that uses neural networks with multiple layers (deep neural networks) to progressively extract higher-level features from raw input.</p>
                        
                        <h3>Neural Networks Architecture</h3>
                        <ul>
                            <li><strong>Input Layer:</strong> Receives raw data (text, audio, etc.)</li>
                            <li><strong>Hidden Layers:</strong> Multiple processing layers that transform the data</li>
                            <li><strong>Output Layer:</strong> Produces the final prediction or generation</li>
                        </ul>
                        
                        <div class="content-box">
                            <h4>Key Deep Learning Models for NLP</h4>
                            <ul>
                                <li><strong>Transformer Models:</strong> Architecture using self-attention mechanisms (basis for BERT, GPT, T5)</li>
                                <li><strong>Encoder-Decoder:</strong> Processes input sequence to generate output sequence (translation, summarization)</li>
                                <li><strong>Language Models:</strong> Predict probability distributions over sequences of words</li>
                            </ul>
                        </div>
                        
                        <h3>Relevance to Language Revitalization</h3>
                        <p>For Truku Seediq revitalization, deep learning enables:</p>
                        <ul>
                            <li>Processing limited language data efficiently</li>
                            <li>Creating language models that capture grammatical patterns</li>
                            <li>Developing speech recognition systems for elder speakers</li>
                            <li>Generating authentic-sounding speech for teaching tools</li>
                        </ul>
                    </div>
                    <div class="slide-image">
                        <img src="/api/placeholder/650/500" alt="Neural network architecture diagram" />
                        
                        <div class="code-block">
                            <span class="code-comment"># Simple neural network architecture</span><br>
                            model = tf.keras.Sequential([<br>
                            &nbsp;&nbsp;tf.keras.layers.Embedding(vocab_size, embedding_dim),<br>
                            &nbsp;&nbsp;tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),<br>
                            &nbsp;&nbsp;tf.keras.layers.Dense(64, activation='relu'),<br>
                            &nbsp;&nbsp;tf.keras.layers.Dense(output_size)<br>
                            ])
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 9: Fine-tuning for Low-Resource Languages -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">9/19</div>
            </div>
            <div class="slide-content">
                <div class="two-column">
                    <div class="slide-text">
                        <h2>Fine-tuning for Low-Resource Languages</h2>
                        
                        <h3>What is Fine-tuning?</h3>
                        <p>Fine-tuning is the process of taking a pre-trained model and adapting it to a specific task or domain by training it on a smaller, specialized dataset.</p>
                        
                        <div class="content-box">
                            <h4>Challenges for Low-Resource Languages</h4>
                            <ul>
                                <li>Limited text and audio data available</li>
                                <li>Lack of representation in pre-training datasets</li>
                                <li>Unique linguistic features not captured in general models</li>
                                <li>Resource constraints for full model training</li>
                            </ul>
                        </div>
                        
                        <h3>Parameter-Efficient Fine-tuning (PEFT)</h3>
                        <p>Our approach for Truku Seediq uses efficient techniques that update only a small subset of model parameters:</p>
                        <ul>
                            <li><strong>Low-Rank Adaptation (LoRA):</strong> Adds trainable rank decomposition matrices</li>
                            <li><strong>Prompt Tuning:</strong> Learns continuous prompt vectors while keeping the model frozen</li>
                            <li><strong>Adapter Layers:</strong> Inserts small trainable modules between existing layers</li>
                        </ul>
                        
                        <h3>Implementation for Truku Seediq</h3>
                        <p>We apply these techniques to develop:</p>
                        <ul>
                            <li>Language models that understand Truku grammatical structures</li>
                            <li>Text-to-speech systems tuned to authentic pronunciation</li>
                            <li>Translation models between Truku, Mandarin, and English</li>
                        </ul>
                    </div>
                    <div class="slide-image">
                        <img src="/api/placeholder/650/300" alt="Fine-tuning diagram for low-resource languages" />
                        
                        <div class="flow-diagram">
                            <img src="/api/placeholder/650/200" alt="Parameter-efficient fine-tuning workflow" />
                        </div>
                        
                        <div class="content-box">
                            <h4>Results from Preliminary Tests</h4>
                            <p>Initial fine-tuning of multilingual models on Pastor Chang's Bible translations has shown promising results, with models beginning to capture Truku-specific patterns after just 500 training steps.</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 10: Retrieval Augmented Generation (RAG) -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">10/19</div>
            </div>
            <div class="slide-content">
                <div class="two-column">
                    <div class="slide-text">
                        <h2>Retrieval Augmented Generation (RAG)</h2>
                        
                        <h3>What is RAG?</h3>
                        <p>Retrieval Augmented Generation (RAG) is a hybrid framework that enhances language models by retrieving relevant information from external knowledge sources and using it to generate more accurate, factual responses.</p>
                        
                        <h3>RAG Architecture</h3>
                        <ol>
                            <li><strong>Retriever:</strong> Searches through a knowledge base for relevant information</li>
                            <li><strong>Generator:</strong> Uses the retrieved information alongside the query to produce informed responses</li>
                            <li><strong>Knowledge Base:</strong> Contains verified information (cultural knowledge, correct language usage)</li>
                        </ol>
                        
                        <div class="content-box">
                            <h4>Benefits for Language Revitalization</h4>
                            <ul>
                                <li><strong>Cultural Accuracy:</strong> Ensures AI responses respect cultural norms and traditional knowledge</li>
                                <li><strong>Language Authenticity:</strong> Anchors language generation in verified, elder-approved texts</li>
                                <li><strong>Source Attribution:</strong> Maintains connection to original language sources</li>
                                <li><strong>Dynamic Updates:</strong> New language materials can be added to knowledge base without retraining</li>
                            </ul>
                        </div>
                        
                        <h3>Truku Seediq RAG Implementation</h3>
                        <p>Our RAG system for Truku language teaching includes:</p>
                        <ul>
                            <li>Bible translation corpus from Pastor Chang</li>
                            <li>Traditional stories and cultural narratives</li>
                            <li>Linguistic documentation from Dr. Tang's research</li>
                            <li>Community-verified lexical and grammatical references</li>
                        </ul>
                    </div>
                    <div class="slide-image">
                        <img src="/api/placeholder/650/300" alt="RAG architecture diagram" />
                        
                        <div class="flow-diagram">
                            <img src="/api/placeholder/650/200" alt="RAG workflow for Truku revitalization" />
                        </div>
                        
                        <div class="code-block">
                            <span class="code-comment"># RAG query processing pseudocode</span><br>
                            def process_query(query, corpus):<br>
                            &nbsp;&nbsp;# Convert query to embedding<br>
                            &nbsp;&nbsp;query_embedding = embed(query)<br>
                            &nbsp;&nbsp;# Retrieve relevant passages<br>
                            &nbsp;&nbsp;relevant_docs = retrieve(query_embedding, corpus)<br>
                            &nbsp;&nbsp;# Generate response using LLM<br>
                            &nbsp;&nbsp;response = generate(query, relevant_docs)<br>
                            &nbsp;&nbsp;return response
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 11: Building Digital Infrastructure - Corpus -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">11/19</div>
            </div>
            <div class="slide-content">
                <div class="two-column">
                    <div class="slide-text">
                        <h2>Building Digital Infrastructure</h2>
                        
                        <h3>Corpus Development</h3>
                        <p>As outlined in the OS科研4 project plan, comprehensive corpus development with physiological indices is the foundation for both AI-powered language revitalization and brain processing research.</p>
                        
                        <div class="ai-method">
                            <h4>
                                <div class="source-image">
                                    <img src="/api/placeholder/40/40" alt="Written documents" />
                                </div>
                                Written Sources
                            </h4>
                            <ul>
                                <li>Books and academic papers (31+ collected sources)</li>
                                <li>Biblical translations (extensive material from Pastor Chang)</li>
                                <li>Government documents</li>
                                <li>Pear Film narratives</li>
                            </ul>
                        </div>
                        
                        <div class="ai-method">
                            <h4>
                                <div class="source-image">
                                    <img src="/api/placeholder/40/40" alt="Audio recording" />
                                </div>
                                Spoken Data
                            </h4>
                            <ul>
                                <li>Archival recordings</li>
                                <li>Field recordings from 2025 data collection with Pastor Chang</li>
                                <li>Natural conversations, traditional narratives, songs</li>
                                <li>Audio-visual data from fieldwork by Prof. Manami Sato</li>
                            </ul>
                        </div>
                        
                        <div class="ai-method">
                            <h4>
                                <div class="source-image">
                                    <img src="/api/placeholder/40/40" alt="Annotated text" />
                                </div>
                                Multi-layered Annotation
                            </h4>
                            <ul>
                                <li>Standardized orthographic transcription</li>
                                <li>Parallel translations</li>
                                <li>Morphological tagging</li>
                                <li>Syntactic annotation</li>
                                <li>Physiological indices for language processing research</li>
                            </ul>
                        </div>
                    </div>
                    <div class="slide-image">
                        <img src="/api/placeholder/650/500" alt="Digital corpus of Truku Seediq language data" />
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 12: Neural Machine Translation -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">12/19</div>
            </div>
            <div class="slide-content">
                <div class="two-column">
                    <div class="slide-text">
                        <h2>Neural Machine Translation (NMT)</h2>
                        
                        <h3>Function & Purpose</h3>
                        <p>Development of neural machine translation systems between Truku Seediq and Mandarin Chinese/English to support digital access, documentation, and learning.</p>
                        
                        <div class="ai-method">
                            <h4>Technical Approach</h4>
                            <ul>
                                <li><strong>Model Architecture:</strong> Transfer learning from multilingual models (MarianMT)</li>
                                <li><strong>Data Augmentation:</strong> Techniques to expand limited parallel text data</li>
                                <li><strong>Morphologically-Aware Modeling:</strong> Special handling for Truku's complex morphology</li>
                            </ul>
                        </div>
                        
                        <div class="ai-method">
                            <h4>Challenges</h4>
                            <ul>
                                <li><strong>Limited Data:</strong> Small parallel corpus compared to high-resource languages</li>
                                <li><strong>Complex Morphology:</strong> Handling voice system and affixation patterns</li>
                                <li><strong>Evaluation Metrics:</strong> Developing appropriate evaluation for Truku quality</li>
                            </ul>
                        </div>
                        
                        <div class="content-box">
                            <h4>Lessons from Related Projects</h4>
                            <p>Drawing from experiences with other endangered language translation projects (e.g., Japanese-Ainu with SacreBLEU score of 32.905), the Truku Seediq model requires approximately 400,000+ words of parallel text for effective performance.</p>
                        </div>
                    </div>
                    <div class="slide-image">
                        <img src="/api/placeholder/650/500" alt="Neural Machine Translation architecture diagram" />
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 13: ASR and Speech Generation -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">13/19</div>
            </div>
            <div class="slide-content">
                <div class="full-width">
                    <h2>Automatic Speech Recognition (ASR) & Speech Generation</h2>
                    
                    <h3>Function & Purpose</h3>
                    <p>Development of models to transcribe spoken Truku Seediq into text and generate natural Truku speech from text, supporting documentation and interactive learning.</p>
                    
                    <div class="ai-method">
                        <h4>Technical Approach</h4>
                        <ul>
                            <li><strong>Model Architecture:</strong> Fine-tuning self-supervised models like OpenAI's Whisper</li>
                            <li><strong>Audio Data Augmentation:</strong> Techniques to expand limited speech data</li>
                            <li><strong>Speaker Diversity:</strong> Including multiple generations and dialectal variations</li>
                        </ul>
                    </div>
                    
                    <h3>Applications</h3>
                    <ul>
                        <li>Accelerating documentation of elder speakers</li>
                        <li>Creating searchable speech corpora</li>
                        <li>Enabling voice interfaces for educational applications</li>
                        <li>Bridging oral and written traditions</li>
                        <li>Supporting pronunciation training through audio feedback</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Slide 14: HeyGen AI Avatar Project -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">14/19</div>
            </div>
            <div class="slide-content">
                <div class="two-column">
                    <div class="slide-text">
                        <h2>HeyGen AI Avatar Project</h2>
                        
                        <div class="content-box">
                            <h4>Specialized Data Collection</h4>
                            <p>February 2025 field work with Pastor Chang to gather high-quality audio-visual data specifically for training AI avatars</p>
                        </div>
                        
                        <h3>Implementation</h3>
                        <p>Creation of virtual Truku language tutors providing interactive learning experiences that preserve cultural knowledge through digital elder storytelling.</p>
                        
                        <h3>Applications</h3>
                        <ul>
                            <li>Interactive conversation practice for language learners</li>
                            <li>Accessible language models when native speakers unavailable</li>
                            <li>Engaging educational content for younger generations</li>
                            <li>Bridging geographic gaps for urban Truku community members</li>
                            <li>Preservation of cultural knowledge and oral traditions</li>
                        </ul>
                        
                        <div class="content-box">
                            <h4>Current Status</h4>
                            <p>Initial community testing shows positive feedback, with continued refinement based on community input and expanding to multiple speakers representing different ages and dialect variants.</p>
                        </div>
                    </div>
                    <div class="slide-image">
                        <img src="/api/placeholder/650/500" alt="HeyGen AI Avatar for Truku language learning" />
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 15: Additional AI Tools -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">15/19</div>
            </div>
            <div class="slide-content">
                <div class="full-width">
                    <h2>Additional AI Tools</h2>
                    
                    <div class="ai-method">
                        <h4>SUNO AI Songs</h4>
                        <p>AI-generated musical language learning resources that combine traditional melodies with linguistic content.</p>
                    </div>
                    
                    <div class="ai-method">
                        <h4>Educational Software</h4>
                        <ul>
                            <li>Interactive learning modules with speech recognition</li>
                            <li>Grammar visualization tools</li>
                            <li>Automated feedback systems for learners</li>
                            <li>Gamified learning experiences</li>
                        </ul>
                    </div>
                    
                    <div class="ai-method">
                        <h4>Digital Dictionary with NLP Integration</h4>
                        <p>Comprehensive digital lexicon with advanced search capabilities, example concordances, and contextual learning materials.</p>
                    </div>
                    
                    <h3>Community-Centered AI Development</h3>
                    <ul>
                        <li>All tools co-designed with community stakeholders</li>
                        <li>Regular feedback loops for improvement</li>
                        <li>Technical training for community members</li>
                        <li>Priority access for community use</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Slide 16: Community-Based Participatory Research Model -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">16/19</div>
            </div>
            <div class="slide-content">
                <div class="full-width">
                    <h2>Community-Based Participatory Research Model</h2>
                    
                    <h3>Foundational Principles</h3>
                    <ul>
                        <li><strong>Community Centrality:</strong> Prioritizing community needs, aspirations, and protocols</li>
                        <li><strong>Decolonizing Research:</strong> Challenging extractive models, centering indigenous knowledge</li>
                        <li><strong>Reciprocal Relationships:</strong> Building long-term partnerships based on trust and mutual benefit</li>
                        <li><strong>Capacity Building:</strong> Empowering community through technology transfer and knowledge sharing</li>
                    </ul>
                    
                    <h3>Implementation Mechanisms</h3>
                    <ul>
                        <li><strong>Co-Design:</strong> Community members actively shaping tool features and interfaces</li>
                        <li><strong>Technical Training:</strong> Workshops on corpus annotation, digital resource management</li>
                        <li><strong>Regular Consultation:</strong> Ongoing dialogue to ensure alignment with community goals</li>
                        <li><strong>Data Sovereignty:</strong> Community control over language data and intellectual property</li>
                    </ul>
                    
                    <div class="content-box">
                        <h4>Recent Example: HeyGen Avatar Development</h4>
                        <p>Pastor Chang's active collaboration in February 2025 field trip, providing cultural guidance on appropriate representation and linguistic authenticity.</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 17: Current Challenges -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">17/19</div>
            </div>
            <div class="slide-content">
                <div class="full-width">
                    <h2>Current Challenges</h2>
                    
                    <div class="ai-method">
                        <h4>Data Scarcity</h4>
                        <ul>
                            <li>Limited digital corpus compared to high-resource languages</li>
                            <li>Need for ~400,000+ words for effective NMT performance</li>
                            <li>Challenges in capturing diverse speech data across generations</li>
                        </ul>
                    </div>
                    
                    <div class="ai-method">
                        <h4>Technical Complexity</h4>
                        <ul>
                            <li>Adapting NLP methods for Truku's complex linguistic structures</li>
                            <li>Balancing standardization with dialect variation</li>
                            <li>Handling intergenerational language differences in AI models</li>
                        </ul>
                    </div>
                    
                    <div class="ai-method">
                        <h4>Resource Limitations</h4>
                        <ul>
                            <li>Infrastructure requirements for AI development</li>
                            <li>Securing sustainable funding for long-term preservation</li>
                            <li>Building technical capacity within the community</li>
                        </ul>
                    </div>
                    
                    <div class="ai-method">
                        <h4>Digital Divide</h4>
                        <ul>
                            <li>Ensuring equitable access to technology within the community</li>
                            <li>Developing user-friendly interfaces for all generations</li>
                            <li>Bridging urban-rural technological gaps</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 18: Future Research Directions -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">18/19</div>
            </div>
            <div class="slide-content">
                <div class="full-width">
                    <h2>Future Research Directions</h2>
                    
                    <div class="timeline">
                        <div class="timeline-item">
                            <h4>Model Refinement & Expansion</h4>
                            <div class="timeline-date">2025-2026</div>
                            <p>Improving NMT and ASR performance through specialized architectures; expanding HeyGen avatars to include more speakers and cultural contexts</p>
                        </div>
                        
                        <div class="timeline-item">
                            <h4>Target Audience Adaptation</h4>
                            <div class="timeline-date">2026-2027</div>
                            <p>Focusing on younger generations with limited Truku exposure; developing age-appropriate learning materials</p>
                        </div>
                        
                        <div class="timeline-item">
                            <h4>Pedagogical Assessment</h4>
                            <div class="timeline-date">2027-2028</div>
                            <p>Evaluating AI tools' effectiveness for language acquisition; refining based on learning outcomes</p>
                        </div>
                        
                        <div class="timeline-item">
                            <h4>Unified Platform Integration</h4>
                            <div class="timeline-date">2028+</div>
                            <p>Creating comprehensive platforms combining multiple language technologies; sharing methodologies with other endangered Formosan languages</p>
                        </div>
                    </div>
                    
                    <div class="content-box">
                        <h4>Knowledge Transfer Potential</h4>
                        <p>Methodologies developed for Truku Seediq can be adapted for other endangered Formosan languages, creating a scalable model for AI-powered language revitalization.</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 19: Conclusion -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">19/19</div>
            </div>
            <div class="slide-content">
                <div class="full-width">
                    <h2>Conclusion</h2>
                    
                    <p>Our research demonstrates how ethically implemented AI technologies can empower indigenous communities in their language revitalization efforts. By combining cutting-edge NLP methods with deep community partnership, we are creating a sustainable framework for Truku Seediq language revitalization that honors both linguistic heritage and technological innovation.</p>
                    
                    <h3>Key Innovations</h3>
                    <ul>
                        <li>Development of specialized corpora and Universal Dependencies treebank</li>
                        <li>Neural machine translation between Truku, Mandarin, and English</li>
                        <li>Speech recognition and generation models adapted for Truku phonology</li>
                        <li>HeyGen AI avatars preserving cultural knowledge through digital elder storytelling</li>
                        <li>Community-centered research model ensuring data sovereignty and ethical implementation</li>
                    </ul>
                    
                    <div class="content-box">
                        <h4>Acknowledgements</h4>
                        <p>We express our sincere gratitude to the Taiwan Truku Cultural Promotion Association, Pastor Chang, Dr. Apay Ai-yu Tang, and the Truku Seediq community for their invaluable contributions to this research.</p>
                    </div>
                    
                    <div class="citation">
                        Field-based Approaches to Language, Cognition, and Human Nature (FALCOHN)<br>
                        OS科研4 (2024-2027) - JSPS Kakenhi Grant-in-Aid (A)<br>
                        Led by Prof. Masatoshi Koizumi (Tohoku University)<br>
                        Research Team: So Miyagawa, Manami Sato, Akinori Ito, and fellow researchers working on Kaqchikel, Tongan, and Oki-no-Erabu languages
                    </div>
                </div>
            </div>
        </div>
    </div>

    <div class="navigation">
        <button class="nav-btn" id="prev-btn">← Previous</button>
        <div class="dots-container" id="dots-container"></div>
        <button class="nav-btn" id="next-btn">Next →</button>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const slides = document.querySelectorAll('.slide');
            const prevBtn = document.getElementById('prev-btn');
            const nextBtn = document.getElementById('next-btn');
            const progressBar = document.getElementById('progressBar');
            const dotsContainer = document.getElementById('dots-container');
            
            let currentSlideIndex = 0;
            const totalSlides = slides.length;
            
            // Create dot indicators
            for (let i = 0; i < totalSlides; i++) {
                const dot = document.createElement('div');
                dot.classList.add('dot');
                dot.setAttribute('data-index', i);
                dot.addEventListener('click', () => {
                    currentSlideIndex = i;
                    showCurrentSlide();
                });
                dotsContainer.appendChild(dot);
            }
            
            // Update slide numbers in headers
            slides.forEach((slide, index) => {
                const slideNumber = slide.querySelector('.slide-number');
                if (slideNumber) {
                    slideNumber.textContent = `${index + 1}/${totalSlides}`;
                }
            });
            
            // Update progress bar
            function updateProgressBar() {
                const progress = ((currentSlideIndex + 1) / totalSlides) * 100;
                progressBar.style.width = `${progress}%`;
            }
            
            // Update button states
            function updateButtonStates() {
                prevBtn.disabled = currentSlideIndex === 0;
                nextBtn.disabled = currentSlideIndex === slides.length - 1;
            }
            
            // Update dots
            function updateDots() {
                const dots = document.querySelectorAll('.dot');
                dots.forEach((dot, index) => {
                    if (index === currentSlideIndex) {
                        dot.classList.add('active');
                    } else {
                        dot.classList.remove('active');
                    }
                });
            }
            
            // Show current slide and hide others
            function showCurrentSlide() {
                slides.forEach((slide, index) => {
                    if (index === currentSlideIndex) {
                        slide.classList.add('active');
                        slide.classList.remove('prev');
                    } else if (index < currentSlideIndex) {
                        slide.classList.remove('active');
                        slide.classList.add('prev');
                    } else {
                        slide.classList.remove('active');
                        slide.classList.remove('prev');
                    }
                });
                
                updateProgressBar();
                updateButtonStates();
                updateDots();
            }
            
            // Move to previous slide
            prevBtn.addEventListener('click', function() {
                if (currentSlideIndex > 0) {
                    currentSlideIndex--;
                    showCurrentSlide();
                }
            });
            
            // Move to next slide
            nextBtn.addEventListener('click', function() {
                if (currentSlideIndex < slides.length - 1) {
                    currentSlideIndex++;
                    showCurrentSlide();
                }
            });
            
            // Keyboard navigation
            document.addEventListener('keydown', function(event) {
                if (event.key === 'ArrowLeft') {
                    if (currentSlideIndex > 0) {
                        currentSlideIndex--;
                        showCurrentSlide();
                    }
                } else if (event.key === 'ArrowRight') {
                    if (currentSlideIndex < slides.length - 1) {
                        currentSlideIndex++;
                        showCurrentSlide();
                    }
                }
            });
            
            // Initial setup
            updateButtonStates();
            updateProgressBar();
            updateDots();
        });
    </script>
</body>
</html>