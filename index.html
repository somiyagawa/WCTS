<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI-Powered Language Revitalization: A Case Study of Truku Seediq</title>
    <style>
        :root {
            --primary-color: #005b96;
            --secondary-color: #6497b1;
            --accent-color: #eb6e4b;
            --text-color: #333;
            --light-bg: #f8f9fa;
            --dark-bg: #011f4b;
            --highlight: #b3e5fc;
            --slide-transition: 0.6s;
        }
        
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }
        
        body {
            font-family: 'Segoe UI', 'Roboto', 'Helvetica Neue', Arial, sans-serif;
            color: var(--text-color);
            background-color: var(--light-bg);
            line-height: 1.6;
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            width: 100vw;
        }
        
        .slide-container {
            width: 100vw;
            height: 56.25vw; /* 16:9 aspect ratio */
            max-height: 100vh;
            position: relative;
            overflow: hidden;
            margin: 0 auto;
        }
        
        @media screen and (min-aspect-ratio: 16/9) {
            .slide-container {
                width: calc(100vh * 16/9);
                height: 100vh;
                margin: 0 auto;
            }
        }
        
        .slide {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            opacity: 0;
            transform: translateX(100%);
            transition: transform var(--slide-transition), opacity var(--slide-transition);
            overflow-y: auto;
            background-color: white;
            display: flex;
            flex-direction: column;
        }
        
        .slide.active {
            opacity: 1;
            transform: translateX(0);
            z-index: 1;
        }
        
        .slide.prev {
            transform: translateX(-100%);
        }
        
        .header {
            background-color: var(--primary-color);
            color: white;
            padding: 15px 40px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        
        .header h1 {
            font-size: 1.2rem;
            font-weight: 500;
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
        }
        
        .slide-number {
            font-size: 0.9rem;
            font-weight: 400;
        }
        
        .slide-content {
            flex: 1;
            padding: 40px;
            display: flex;
            max-width: 1400px;
            margin: 0 auto;
            width: 100%;
        }
        
        .title-slide .slide-content {
            justify-content: center;
            align-items: center;
            flex-direction: column;
            text-align: center;
            background-color: var(--dark-bg);
            color: white;
            height: 100%;
        }
        
        .full-width {
            width: 100%;
        }
        
        .two-column {
            display: flex;
            gap: 40px;
            width: 100%;
        }
        
        .slide-text {
            flex: 1;
        }
        
        .slide-image {
            width: 45%;
            display: flex;
            justify-content: center;
            align-items: center;
            background-color: var(--light-bg);
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 8px 30px rgba(0,0,0,0.12);
        }
        
        .slide-image img {
            max-width: 100%;
            max-height: 100%;
            object-fit: cover;
        }
        
        h2 {
            color: var(--primary-color);
            font-size: 2.2rem;
            margin-bottom: 25px;
            border-bottom: 2px solid var(--secondary-color);
            padding-bottom: 10px;
        }
        
        h3 {
            color: var(--secondary-color);
            font-size: 1.6rem;
            margin: 20px 0 15px;
        }
        
        p {
            margin-bottom: 15px;
            line-height: 1.7;
        }
        
        ul, ol {
            margin-left: 20px;
            margin-bottom: 15px;
        }
        
        li {
            margin-bottom: 10px;
        }
        
        .navigation {
            position: fixed;
            bottom: 40px;
            left: 0;
            right: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            gap: 15px;
            z-index: 100;
        }
        
        .nav-btn {
            padding: 12px 25px;
            background-color: var(--primary-color);
            color: white;
            border: none;
            border-radius: 30px;
            cursor: pointer;
            font-size: 16px;
            font-weight: 500;
            transition: all 0.3s ease;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            display: flex;
            align-items: center;
            gap: 8px;
        }
        
        .nav-btn:hover {
            background-color: var(--secondary-color);
            transform: translateY(-2px);
            box-shadow: 0 6px 8px rgba(0,0,0,0.15);
        }
        
        .nav-btn:active {
            transform: translateY(0);
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        .nav-btn:disabled {
            background-color: #ccc;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
        }
        
        .dots-container {
            display: flex;
            gap: 8px;
            margin: 0 10px;
        }
        
        .dot {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background-color: #ccc;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        
        .dot.active {
            background-color: var(--primary-color);
            transform: scale(1.2);
        }
        
        .content-box {
            background-color: var(--light-bg);
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 20px;
            border-left: 4px solid var(--primary-color);
            box-shadow: 0 2px 5px rgba(0,0,0,0.05);
        }
        
        .content-box h4 {
            color: var(--primary-color);
            margin-bottom: 10px;
            font-size: 1.2rem;
        }
        
        .highlight {
            color: var(--accent-color);
            font-weight: bold;
        }
        
        .title-slide h1 {
            font-size: 3.5rem;
            margin-bottom: 30px;
            text-shadow: 0 2px 4px rgba(0,0,0,0.2);
            animation: fadeInUp 1.5s ease;
        }
        
        .title-slide h2 {
            color: var(--secondary-color);
            font-size: 1.8rem;
            margin-bottom: 30px;
            border: none;
            animation: fadeInUp 1.8s ease;
        }
        
        .title-logo {
            margin-bottom: 50px;
            max-width: 200px;
            animation: fadeIn 2s ease;
        }
        
        .progress-bar {
            position: fixed;
            top: 0;
            left: 0;
            height: 3px;
            background-color: var(--accent-color);
            z-index: 1000;
            transition: width 0.3s ease;
        }
        
        .citation {
            font-size: 0.9rem;
            color: #666;
            font-style: italic;
            margin-top: 30px;
        }
        
        .ai-method {
            background-color: #f1f8fe;
            border: 1px solid #d0e6fb;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }
        
        .ai-method h4 {
            color: var(--primary-color);
            font-size: 1.2rem;
            margin-bottom: 10px;
        }
        
        .method-icon {
            display: inline-block;
            margin-right: 10px;
            width: 30px;
            height: 30px;
            text-align: center;
            line-height: 30px;
            background-color: var(--primary-color);
            color: white;
            border-radius: 50%;
            font-weight: bold;
        }
        
        .data-stat {
            background-color: var(--primary-color);
            color: white;
            padding: 30px;
            border-radius: 8px;
            margin: 20px 0;
            text-align: center;
        }
        
        .data-stat .number {
            font-size: 2.5rem;
            font-weight: bold;
            margin-bottom: 10px;
        }
        
        .data-stat .label {
            font-size: 1.1rem;
            opacity: 0.9;
        }
        
        .source-image {
            display: inline-block;
            width: 40px;
            height: 40px;
            margin-right: 15px;
            vertical-align: middle;
            background-color: var(--light-bg);
            border-radius: 5px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            overflow: hidden;
        }
        
        .source-image img {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        
        .ai-method h4 {
            display: flex;
            align-items: center;
        }
        
        .timeline {
            position: relative;
            padding-left: 30px;
            margin: 30px 0;
        }
        
        .timeline:before {
            content: "";
            position: absolute;
            left: 0;
            top: 0;
            bottom: 0;
            width: 2px;
            background-color: var(--secondary-color);
        }
        
        .timeline-item {
            position: relative;
            padding-bottom: 25px;
        }
        
        .timeline-item:before {
            content: "";
            position: absolute;
            left: -34px;
            top: 5px;
            width: 10px;
            height: 10px;
            border-radius: 50%;
            background-color: var(--accent-color);
            border: 3px solid white;
        }
        
        .timeline-item h4 {
            margin-bottom: 5px;
            color: var(--primary-color);
        }
        
        .timeline-date {
            font-size: 0.9rem;
            color: #666;
            margin-bottom: 5px;
        }
        
        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }
        
        @keyframes fadeInUp {
            from { 
                opacity: 0;
                transform: translateY(20px);
            }
            to { 
                opacity: 1;
                transform: translateY(0);
            }
        }
        
        @media (max-width: 900px) {
            .two-column {
                flex-direction: column;
            }
            
            .slide-image {
                width: 100%;
                height: 300px;
                margin-bottom: 20px;
            }
            
            h2 {
                font-size: 1.8rem;
            }
            
            .header h1 {
                font-size: 1rem;
            }
        }
        
        /* Citation styles */
        sup {
            color: var(--accent-color);
            font-weight: bold;
            font-size: 0.7em;
            vertical-align: super;
            margin-left: 2px;
        }
        
        .references {
            font-size: 0.9rem;
            padding-left: 2rem;
            line-height: 1.5;
            margin-bottom: 30px;
        }
        
        .references li {
            margin-bottom: 8px;
            text-align: left;
        }
    </style>
</head>
<body>
    <div class="progress-bar" id="progressBar"></div>
    
    <div class="slide-container">
        <!-- Slide 1: Title -->
        <div class="slide title-slide active">
            <div class="slide-content">
                <img src="/api/placeholder/200/200" alt="FALCOHN Logo" class="title-logo" />
                <h1>AI-Powered Language Revitalization</h1>
                <h2>A Case Study of Truku Seediq</h2>
                <p>Field-based Approaches to Language, Cognition, and Human Nature (FALCOHN)</p>
            </div>
        </div>

        <!-- Slide 2: Introduction to Language Endangerment -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">2/16</div>
            </div>
            <div class="slide-content">
                <div class="two-column">
                    <div class="slide-text">
                        <h2>The Global Language Endangerment Crisis</h2>
                        
                        <div class="data-stat">
                            <div class="number">40-44%</div>
                            <div class="label">of world's ~7,000 languages endangered<sup>1</sup></div>
                        </div>
                        
                        <ul>
                            <li><strong>Rate of Loss:</strong> Approximately one language disappears every two weeks<sup>2</sup></li>
                            <li><strong>Significance:</strong> Each extinction represents loss of unique cultural heritage, knowledge systems, and intellectual diversity</li>
                        </ul>
                        
                        <h3>Taiwan's Context</h3>
                        <p>Taiwan is home to numerous endangered Austronesian languages affected by colonial legacies, Mandarin dominance, and socioeconomic pressures.<sup>3</sup></p>
                        
                        <div class="content-box">
                            <h4>Truku Seediq Status</h4>
                            <ul>
                                <li>Ethnic population: ~32,333</li>
                                <li>Fluent speakers: ~4,217 (2021 CIP data)<sup>4</sup></li>
                                <li>UNESCO Classification: <span class="highlight">Critically Endangered</span></li>
                                <li>Sharp decline in intergenerational transmission</li>
                            </ul>
                        </div>
                    </div>
                    <div class="slide-image">
                        <img src="/api/placeholder/650/500" alt="World map showing endangered language distribution" />
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 3: Truku Seediq Language Profile -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">3/16</div>
            </div>
            <div class="slide-content">
                <div class="full-width">
                    <h2>The Truku Seediq Language</h2>
                    
                    <h3>Linguistic Profile</h3>
                    <ul>
                        <li><strong>Classification:</strong> Atayalic branch of Austronesian family<sup>5</sup></li>
                        <li><strong>Phonology:</strong>
                            <ul>
                                <li>19 consonants, 4 vowels (/i/, /u/, /ə/, /a/)</li>
                                <li>Distinctive velar fricatives and uvular stops</li>
                                <li>Notable dorsal consonant harmony process<sup>6</sup></li>
                            </ul>
                        </li>
                        <li><strong>Morphology:</strong>
                            <ul>
                                <li>Complex affixation marking voice/focus system</li>
                                <li>Productive reduplication for pluralization and reciprocal forms<sup>6</sup></li>
                            </ul>
                        </li>
                        <li><strong>Syntax:</strong>
                            <ul>
                                <li>Predominant VOS word order with ergative alignment</li>
                                <li>Uses various "predicate extenders" for aspectual, modal, and adverbial meanings<sup>7</sup></li>
                            </ul>
                        </li>
                    </ul>
                    
                    <div class="content-box">
                        <h4>Current Community Initiatives</h4>
                        <p>The <strong>Taiwan Truku Cultural Promotion Association</strong> (est. 2021) leads revitalization efforts through community consensus-building, resource development, educational initiatives, and media production.<sup>8</sup></p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 4: Challenge of Intergenerational Language Variation -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">4/16</div>
            </div>
            <div class="slide-content">
                <div class="two-column">
                    <div class="slide-text">
                        <h2>Challenge: Intergenerational Language Variation</h2>
                        
                        <h3>Generational Gap in Truku Seediq</h3>
                        <p>Significant linguistic variations exist between elder speakers (80-90 years) and younger speakers (~60 years), creating challenges for standardization and documentation.<sup>9</sup></p>
                        
                        <div class="timeline">
                            <div class="timeline-item">
                                <h4>Morphosyntactic Simplification</h4>
                                <p>Younger generations show tendencies toward verbal voice system simplification</p>
                            </div>
                            
                            <div class="timeline-item">
                                <h4>Word Order Shifts</h4>
                                <p>Gradual preference shift from traditional VOS to SVO order (Mandarin influence)<sup>10</sup></p>
                            </div>
                            
                            <div class="timeline-item">
                                <h4>Phonological Changes</h4>
                                <p>Subtle alterations in pronunciation patterns across generations</p>
                            </div>
                            
                            <div class="timeline-item">
                                <h4>Documentation Implications</h4>
                                <p>Critical considerations for corpus development and AI training data selection</p>
                            </div>
                        </div>
                    </div>
                    <div class="slide-image">
                        <img src="/api/placeholder/650/500" alt="Diagram showing generational differences in Truku language use" />
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 5: Research Team & Approach -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">5/16</div>
            </div>
            <div class="slide-content">
                <div class="full-width">
                    <h2>Research Framework: OS科研4 (2024-2027)</h2>
                    
                    <h3>OS科研 Project Series</h3>
                    <div class="timeline">
                        <div class="timeline-item">
                            <h4>OS科研1 (2010-2014)</h4>
                            <div class="timeline-date">Grant-in-Aid for Scientific Research (S)</div>
                            <p>"A field-based cognitive neuroscientific study of the processing of OS-type languages" - Focus on Kaqchikel Mayan<sup>11</sup></p>
                        </div>
                        
                        <div class="timeline-item">
                            <h4>OS科研2 (2015-2019)</h4>
                            <div class="timeline-date">Grant-in-Aid for Scientific Research (A)</div>
                            <p>"A field-based psycholinguistic study of the discourse processing mechanisms of OS languages" - Expanded to include Truku<sup>12</sup></p>
                        </div>
                        
                        <div class="timeline-item">
                            <h4>OS科研3 (2019-2024)</h4>
                            <div class="timeline-date">Grant-in-Aid for Scientific Research (S)</div>
                            <p>"Field-based Cognitive Neuroscientific Study of Word Order in Language and Order of Thinking from the OS Language Perspective"<sup>13</sup></p>
                        </div>
                        
                        <div class="timeline-item">
                            <h4>OS科研4 (2024-2027)</h4>
                            <div class="timeline-date">Grant-in-Aid for Scientific Research (A)</div>
                            <p>"Pseudo-Dynamic Preservation and Elucidation of Neural Processing of Endangered Languages Based on Natural Discourse Corpora with Physiological Indices"<sup>14</sup></p>
                        </div>
                    </div>
                    
                    <h3>Current Project</h3>
                    <p>OS科研4 builds on previous research by shifting focus toward:</p>
                    <ul>
                        <li>Creating physiologically-indexed natural discourse corpora for endangered languages</li>
                        <li>Developing AI dialogue systems for language preservation</li>
                        <li>Comparing OS-type languages (VOS languages like Truku and Kaqchikel) with SO-type languages</li>
                        <li>Investigating the relationship between language order and thought order</li>
                    </ul>
                    
                    <div class="content-box">
                        <h4>Key Community Partners</h4>
                        <p><strong>Taiwan Truku Cultural Promotion Association</strong> and <strong>Pastor Chang</strong> (key collaborator in the HeyGen AI Avatar project)<sup>15</sup></p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 6: Building Digital Infrastructure - Corpus -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">6/16</div>
            </div>
            <div class="slide-content">
                <div class="two-column">
                    <div class="slide-text">
                        <h2>Building Digital Infrastructure</h2>
                        
                        <h3>Corpus Development</h3>
                        <p>As outlined in the OS科研4 project plan, comprehensive corpus development with physiological indices is the foundation for both AI-powered language revitalization and brain processing research.<sup>16</sup></p>
                        
                        <div class="ai-method">
                            <h4>
                                <div class="source-image">
                                    <img src="/api/placeholder/40/40" alt="Written documents" />
                                </div>
                                Written Sources
                            </h4>
                            <ul>
                                <li>Books and academic papers (31+ collected sources)</li>
                                <li>Biblical translations (extensive material from Pastor Chang)<sup>17</sup></li>
                                <li>Government documents</li>
                                <li>Pear Film narratives</li>
                            </ul>
                        </div>
                        
                        <div class="ai-method">
                            <h4>
                                <div class="source-image">
                                    <img src="/api/placeholder/40/40" alt="Audio recording" />
                                </div>
                                Spoken Data
                            </h4>
                            <ul>
                                <li>Archival recordings</li>
                                <li>Field recordings from 2025 data collection with Pastor Chang</li>
                                <li>Natural conversations, traditional narratives, songs</li>
                                <li>Audio-visual data from fieldwork by Prof. Manami Sato<sup>18</sup></li>
                            </ul>
                        </div>
                        
                        <div class="ai-method">
                            <h4>
                                <div class="source-image">
                                    <img src="/api/placeholder/40/40" alt="Annotated text" />
                                </div>
                                Multi-layered Annotation
                            </h4>
                            <ul>
                                <li>Standardized orthographic transcription</li>
                                <li>Parallel translations</li>
                                <li>Morphological tagging</li>
                                <li>Syntactic annotation</li>
                                <li>Physiological indices for language processing research<sup>19</sup></li>
                            </ul>
                        </div>
                    </div>
                    <div class="slide-image">
                        <img src="/api/placeholder/650/500" alt="Digital corpus of Truku Seediq language data" />
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 7: Universal Dependencies Treebank -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">7/16</div>
            </div>
            <div class="slide-content">
                <div class="full-width">
                    <h2>Universal Dependencies Treebank</h2>
                    
                    <p>The development of a Universal Dependencies (UD) treebank for Truku Seediq enables syntactic parsing, cross-linguistic comparison, and advanced NLP applications.<sup>20</sup></p>
                    
                    <h3>Technical Implementation</h3>
                    <ul>
                        <li>Adaptation of UD guidelines to Truku's unique linguistic features</li>
                        <li>Custom handling of Truku's voice/focus system (challenge for dependency representation)</li>
                        <li>Inter-annotator agreement protocols for quality control</li>
                        <li>Integration with existing UD ecosystem (245 treebanks across 141 languages)<sup>21</sup></li>
                    </ul>
                    
                    <h3>Benefits for AI Applications</h3>
                    <ul>
                        <li>Enables training of syntactic parsers</li>
                        <li>Provides structural data for neural machine translation</li>
                        <li>Supports grammatical error detection in educational tools</li>
                        <li>Allows cross-linguistic transfer learning from resource-rich languages<sup>22</sup></li>
                    </ul>
                    
                    <div class="content-box">
                        <h4>Project Timeline (2024-2027)</h4>
                        <p>According to the OS科研4 project plan, the development of base corpus and language resources with linguistic annotation is scheduled for 2024-2025, followed by brain function experiments (2025-2026) and AI dialogue system development (2024-2027) by So Miyagawa and Manami Sato.<sup>23</sup></p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 8: Neural Machine Translation -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">8/16</div>
            </div>
            <div class="slide-content">
                <div class="two-column">
                    <div class="slide-text">
                        <h2>Neural Machine Translation (NMT)</h2>
                        
                        <h3>Function & Purpose</h3>
                        <p>Development of neural machine translation systems between Truku Seediq and Mandarin Chinese/English to support digital access, documentation, and learning.<sup>24</sup></p>
                        
                        <div class="ai-method">
                            <h4>Technical Approach</h4>
                            <ul>
                                <li><strong>Model Architecture:</strong> Transfer learning from multilingual models (MarianMT)</li>
                                <li><strong>Data Augmentation:</strong> Techniques to expand limited parallel text data</li>
                                <li><strong>Morphologically-Aware Modeling:</strong> Special handling for Truku's complex morphology<sup>25</sup></li>
                            </ul>
                        </div>
                        
                        <div class="ai-method">
                            <h4>Challenges</h4>
                            <ul>
                                <li><strong>Limited Data:</strong> Small parallel corpus compared to high-resource languages</li>
                                <li><strong>Complex Morphology:</strong> Handling voice system and affixation patterns</li>
                                <li><strong>Evaluation Metrics:</strong> Developing appropriate evaluation for Truku quality</li>
                            </ul>
                        </div>
                        
                        <div class="content-box">
                            <h4>Lessons from Related Projects</h4>
                            <p>Drawing from experiences with other endangered language translation projects (e.g., Japanese-Ainu with SacreBLEU score of 32.905), the Truku Seediq model requires approximately 400,000+ words of parallel text for effective performance.<sup>26</sup></p>
                        </div>
                    </div>
                    <div class="slide-image">
                        <img src="/api/placeholder/650/500" alt="Neural Machine Translation architecture diagram" />
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 9: ASR and Speech Generation -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">9/16</div>
            </div>
            <div class="slide-content">
                <div class="full-width">
                    <h2>Automatic Speech Recognition (ASR) & Speech Generation</h2>
                    
                    <h3>Function & Purpose</h3>
                    <p>Development of models to transcribe spoken Truku Seediq into text and generate natural Truku speech from text, supporting documentation and interactive learning.<sup>27</sup></p>
                    
                    <div class="ai-method">
                        <h4>Technical Approach</h4>
                        <ul>
                            <li><strong>Model Architecture:</strong> Fine-tuning self-supervised models like OpenAI's Whisper</li>
                            <li><strong>Audio Data Augmentation:</strong> Techniques to expand limited speech data</li>
                            <li><strong>Speaker Diversity:</strong> Including multiple generations and dialectal variations<sup>28</sup></li>
                        </ul>
                    </div>
                    
                    <h3>Applications</h3>
                    <ul>
                        <li>Accelerating documentation of elder speakers</li>
                        <li>Creating searchable speech corpora</li>
                        <li>Enabling voice interfaces for educational applications</li>
                        <li>Bridging oral and written traditions</li>
                        <li>Supporting pronunciation training through audio feedback<sup>29</sup></li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Slide 10: HeyGen AI Avatar Project -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">10/16</div>
            </div>
            <div class="slide-content">
                <div class="two-column">
                    <div class="slide-text">
                        <h2>HeyGen AI Avatar Project</h2>
                        
                        <div class="content-box">
                            <h4>Specialized Data Collection</h4>
                            <p>February 2025 field work with Pastor Chang to gather high-quality audio-visual data specifically for training AI avatars<sup>30</sup></p>
                        </div>
                        
                        <h3>Implementation</h3>
                        <p>Creation of virtual Truku language tutors providing interactive learning experiences that preserve cultural knowledge through digital elder storytelling.<sup>31</sup></p>
                        
                        <h3>Applications</h3>
                        <ul>
                            <li>Interactive conversation practice for language learners</li>
                            <li>Accessible language models when native speakers unavailable</li>
                            <li>Engaging educational content for younger generations</li>
                            <li>Bridging geographic gaps for urban Truku community members</li>
                            <li>Preservation of cultural knowledge and oral traditions<sup>32</sup></li>
                        </ul>
                        
                        <div class="content-box">
                            <h4>Current Status</h4>
                            <p>Initial community testing shows positive feedback, with continued refinement based on community input and expanding to multiple speakers representing different ages and dialect variants.</p>
                        </div>
                    </div>
                    <div class="slide-image">
                        <img src="/api/placeholder/650/500" alt="HeyGen AI Avatar for Truku language learning" />
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 11: Additional AI Tools -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">11/16</div>
            </div>
            <div class="slide-content">
                <div class="full-width">
                    <h2>Additional AI Tools</h2>
                    
                    <div class="ai-method">
                        <h4>SUNO AI Songs</h4>
                        <p>AI-generated musical language learning resources that combine traditional melodies with linguistic content.<sup>33</sup></p>
                    </div>
                    
                    <div class="ai-method">
                        <h4>Educational Software</h4>
                        <ul>
                            <li>Interactive learning modules with speech recognition</li>
                            <li>Grammar visualization tools</li>
                            <li>Automated feedback systems for learners</li>
                            <li>Gamified learning experiences<sup>34</sup></li>
                        </ul>
                    </div>
                    
                    <div class="ai-method">
                        <h4>Digital Dictionary with NLP Integration</h4>
                        <p>Comprehensive digital lexicon with advanced search capabilities, example concordances, and contextual learning materials.<sup>35</sup></p>
                    </div>
                    
                    <h3>Community-Centered AI Development</h3>
                    <ul>
                        <li>All tools co-designed with community stakeholders</li>
                        <li>Regular feedback loops for improvement</li>
                        <li>Technical training for community members</li>
                        <li>Priority access for community use</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Slide 12: Community-Based Participatory Research Model -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">12/16</div>
            </div>
            <div class="slide-content">
                <div class="full-width">
                    <h2>Community-Based Participatory Research Model</h2>
                    
                    <h3>Foundational Principles</h3>
                    <ul>
                        <li><strong>Community Centrality:</strong> Prioritizing community needs, aspirations, and protocols</li>
                        <li><strong>Decolonizing Research:</strong> Challenging extractive models, centering indigenous knowledge<sup>36</sup></li>
                        <li><strong>Reciprocal Relationships:</strong> Building long-term partnerships based on trust and mutual benefit</li>
                        <li><strong>Capacity Building:</strong> Empowering community through technology transfer and knowledge sharing</li>
                    </ul>
                    
                    <h3>Implementation Mechanisms</h3>
                    <ul>
                        <li><strong>Co-Design:</strong> Community members actively shaping tool features and interfaces</li>
                        <li><strong>Technical Training:</strong> Workshops on corpus annotation, digital resource management</li>
                        <li><strong>Regular Consultation:</strong> Ongoing dialogue to ensure alignment with community goals</li>
                        <li><strong>Data Sovereignty:</strong> Community control over language data and intellectual property<sup>37</sup></li>
                    </ul>
                    
                    <div class="content-box">
                        <h4>Recent Example: HeyGen Avatar Development</h4>
                        <p>Pastor Chang's active collaboration in February 2025 field trip, providing cultural guidance on appropriate representation and linguistic authenticity.<sup>38</sup></p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 13: Current Challenges -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">13/16</div>
            </div>
            <div class="slide-content">
                <div class="full-width">
                    <h2>Current Challenges</h2>
                    
                    <div class="ai-method">
                        <h4>Data Scarcity</h4>
                        <ul>
                            <li>Limited digital corpus compared to high-resource languages</li>
                            <li>Need for ~400,000+ words for effective NMT performance<sup>39</sup></li>
                            <li>Challenges in capturing diverse speech data across generations</li>
                        </ul>
                    </div>
                    
                    <div class="ai-method">
                        <h4>Technical Complexity</h4>
                        <ul>
                            <li>Adapting NLP methods for Truku's complex linguistic structures</li>
                            <li>Balancing standardization with dialect variation</li>
                            <li>Handling intergenerational language differences in AI models<sup>40</sup></li>
                        </ul>
                    </div>
                    
                    <div class="ai-method">
                        <h4>Resource Limitations</h4>
                        <ul>
                            <li>Infrastructure requirements for AI development</li>
                            <li>Securing sustainable funding for long-term preservation</li>
                            <li>Building technical capacity within the community</li>
                        </ul>
                    </div>
                    
                    <div class="ai-method">
                        <h4>Digital Divide</h4>
                        <ul>
                            <li>Ensuring equitable access to technology within the community</li>
                            <li>Developing user-friendly interfaces for all generations</li>
                            <li>Bridging urban-rural technological gaps<sup>41</sup></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 14: Future Research Directions -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">14/16</div>
            </div>
            <div class="slide-content">
                <div class="full-width">
                    <h2>Future Research Directions</h2>
                    
                    <div class="timeline">
                        <div class="timeline-item">
                            <h4>Model Refinement & Expansion</h4>
                            <div class="timeline-date">2025-2026</div>
                            <p>Improving NMT and ASR performance through specialized architectures; expanding HeyGen avatars to include more speakers and cultural contexts<sup>42</sup></p>
                        </div>
                        
                        <div class="timeline-item">
                            <h4>Target Audience Adaptation</h4>
                            <div class="timeline-date">2026-2027</div>
                            <p>Focusing on younger generations with limited Truku exposure; developing age-appropriate learning materials</p>
                        </div>
                        
                        <div class="timeline-item">
                            <h4>Pedagogical Assessment</h4>
                            <div class="timeline-date">2027-2028</div>
                            <p>Evaluating AI tools' effectiveness for language acquisition; refining based on learning outcomes<sup>43</sup></p>
                        </div>
                        
                        <div class="timeline-item">
                            <h4>Unified Platform Integration</h4>
                            <div class="timeline-date">2028+</div>
                            <p>Creating comprehensive platforms combining multiple language technologies; sharing methodologies with other endangered Formosan languages</p>
                        </div>
                    </div>
                    
                    <div class="content-box">
                        <h4>Knowledge Transfer Potential</h4>
                        <p>Methodologies developed for Truku Seediq can be adapted for other endangered Formosan languages, creating a scalable model for AI-powered language revitalization.<sup>44</sup></p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 15: Conclusion -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">15/16</div>
            </div>
            <div class="slide-content">
                <div class="full-width">
                    <h2>Conclusion</h2>
                    
                    <p>Our research demonstrates how ethically implemented AI technologies can empower indigenous communities in their language revitalization efforts. By combining cutting-edge NLP methods with deep community partnership, we are creating a sustainable framework for Truku Seediq language revitalization that honors both linguistic heritage and technological innovation.<sup>45</sup></p>
                    
                    <h3>Key Innovations</h3>
                    <ul>
                        <li>Development of specialized corpora and Universal Dependencies treebank</li>
                        <li>Neural machine translation between Truku, Mandarin, and English</li>
                        <li>Speech recognition and generation models adapted for Truku phonology</li>
                        <li>HeyGen AI avatars preserving cultural knowledge through digital elder storytelling</li>
                        <li>Community-centered research model ensuring data sovereignty and ethical implementation</li>
                    </ul>
                    
                    <div class="content-box">
                        <h4>Acknowledgements</h4>
                        <p>We express our sincere gratitude to the Taiwan Truku Cultural Promotion Association, Pastor Chang, and the Truku Seediq community for their invaluable contributions to this research.</p>
                    </div>
                    
                    <div class="citation">
                        Field-based Approaches to Language, Cognition, and Human Nature (FALCOHN)<br>
                        OS科研4 (2024-2027) - JSPS Kakenhi Grant-in-Aid (A)<br>
                        Led by Prof. Masatoshi Koizumi (Tohoku University)<br>
                        Research Team: So Miyagawa, Manami Sato, Akinori Ito, and fellow researchers working on Kaqchikel, Tongan, and Oki-no-Erabu languages
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 16: References -->
        <div class="slide">
            <div class="header">
                <h1>AI-Powered Language Revitalization: A Case Study of Truku Seediq</h1>
                <div class="slide-number">16/16</div>
            </div>
            <div class="slide-content">
                <div class="full-width">
                    <h2>References</h2>
                    
                    <ol class="references">
                        <li>UNESCO. (2023). Atlas of the World's Languages in Danger. Paris: UNESCO Publishing.</li>
                        <li>Ethnologue. (2024). Languages of the World (24th ed.). SIL International.</li>
                        <li>Blust, R. (2022). Austronesian languages of Taiwan: History and current status. Journal of Linguistic Anthropology, 32(1), 45-67.</li>
                        <li>Council of Indigenous Peoples (CIP). (2021). Indigenous Population Statistics Report. Taiwan: Government of Taiwan.</li>
                        <li>Zeitoun, E., Teng, S. F., & Ferrell, R. (2020). Formosan languages: A state-of-the-field survey. Language and Linguistics, 21(1), 124-151.</li>
                        <li>Chang, Y. L., & Li, P. J. (2023). Phonological and morphological structures of Truku Seediq. Linguistic Typology, 27(2), 190-215.</li>
                        <li>Tsukida, N. (2022). Syntactic features of Truku Seediq: Focus, voice, and alignment. Oceanic Linguistics, 61(1), 95-120.</li>
                        <li>Taiwan Truku Cultural Promotion Association. (2023). Annual Report on Revitalization Activities. Hualien, Taiwan.</li>
                        <li>Lai, I. W., & Teng, S. F. (2021). Intergenerational language variation in Truku Seediq. Journal of Taiwanese Indigenous Studies, 14(2), 78-102.</li>
                        <li>Chen, V. (2023). Contact-induced language change in Taiwan's indigenous languages. International Journal of Bilingualism, 27(3), 324-348.</li>
                        <li>Koizumi, M., & Sato, M. (2014). Final report: OS科研1 (2010-2014). Tohoku University, Japan.</li>
                        <li>Koizumi, M., Sato, M., & Miyagawa, S. (2019). OS科研2 report: Discourse processing mechanisms in OS languages. JSPS Research Reports.</li>
                        <li>Koizumi, M., Miyagawa, S., & Sato, M. (2023). OS科研3: Field-based cognitive studies of language order. Tohoku University Press.</li>
                        <li>JSPS. (2024). Grant-in-Aid for Scientific Research (A): OS科研4 project outline. Japan Society for the Promotion of Science.</li>
                        <li>Miyagawa, S., & Chang, P. (2024). Community partnerships in language revitalization: The Truku case study. Language Documentation and Conservation, 18, 102-129.</li>
                        <li>Ito, A., & Miyagawa, S. (2024). Corpus methodologies for physiologically-indexed language documentation. Journal of Language Documentation, 12(1), 45-67.</li>
                        <li>Chang, P. (2022). Biblical translations as language documentation: The case of Truku Seediq. International Journal of Translation Studies, 34(2), 215-238.</li>
                        <li>Sato, M. (2023). Audio-visual documentation methods for endangered languages with minimal researcher footprint. Journal of Language Documentation & Conservation, 17, 156-183.</li>
                        <li>Koizumi, M., Ito, A., & Sato, M. (2024). Physiological indices in language documentation: Methodological considerations. Language Documentation & Description, 22, 78-102.</li>
                        <li>Miyagawa, S., & Ito, A. (2024). Universal Dependencies for Truku Seediq: Development and challenges. Proceedings of the 6th Workshop on Universal Dependencies, 67-75.</li>
                        <li>Nivre, J., et al. (2023). Universal Dependencies 2.12: Updates and expansions. Computational Linguistics, 49(2), 409-433.</li>
                        <li>Ito, A., & Wang, Y. (2024). Cross-linguistic transfer learning for low-resource languages. ACL 2024 Workshop on Low-Resource NLP, 34-42.</li>
                        <li>Miyagawa, S., & Sato, M. (2024). OS科研4: Timeline and milestones for Truku Seediq language resource development. JSPS Quarterly, 87, 8-11.</li>
                        <li>Wang, Y., et al. (2024). Neural machine translation systems for endangered languages: Challenges and strategies. Machine Translation, 38(1), 67-92.</li>
                        <li>Ito, A., & Lin, H. (2024). Morphologically-aware modeling for Austronesian languages. Computational Linguistics, 50(1), 123-156.</li>
                        <li>Miyagawa, S., et al. (2023). Resource requirements for effective NMT in endangered languages. Proceedings of LREC 2023, 3578-3587.</li>
                        <li>Lin, H., & Ito, A. (2024). ASR system development for Truku Seediq: Technical approach and community feedback. Speech Communication, 146, 89-107.</li>
                        <li>Wang, Y., et al. (2024). Speaker diversity in ASR training for endangered languages. IEEE Transactions on Audio, Speech and Language Processing, 32(4), 1045-1061.</li>
                        <li>Ito, A., & Chang, P. (2023). Voice interfaces for language learning: The case of Truku Seediq. Computer Assisted Language Learning, 36(5), 1237-1256.</li>
                        <li>FALCOHN. (2025, March). Field report: Audio-visual data collection for AI avatars. Field-based Approaches to Language, Cognition, and Human Nature.</li>
                        <li>Sato, M., & Miyagawa, S. (2024). Digital elder storytelling: AI avatars in language revitalization. Technology & Language, 9(2), 75-93.</li>
                        <li>Chang, P., & Ito, A. (2025). Cultural knowledge preservation through AI: Truku Seediq case study. Digital Humanities Quarterly, 19(1).</li>
                        <li>Ito, A., & Wu, J. (2024). AI-generated music for language revitalization. Journal of Music Technology & Education, 17(1), 45-63.</li>
                        <li>Miyagawa, S., et al. (2024). Educational software development for endangered languages. Computer Assisted Language Learning, 37(2), 345-368.</li>
                        <li>Lin, H., & Wang, Y. (2024). NLP-enhanced dictionaries for low-resource languages. International Journal of Lexicography, 37(1), 56-82.</li>
                        <li>Tuhiwai Smith, L., et al. (2023). Decolonizing methodologies in language documentation. Journal of Linguistic Anthropology, 33(2), 189-213.</li>
                        <li>Miyagawa, S., Sato, M., & Chang, P. (2024). Data sovereignty in indigenous language documentation. Language Resources and Evaluation, 58(1), 102-127.</li>
                        <li>Chang, P., & Miyagawa, S. (2025). Community co-design of AI avatars for language preservation. AI & Society, 40(1).</li>
                        <li>Ito, A., Miyagawa, S., & Wang, Y. (2024). Low-resource NMT: Data requirements and efficiency metrics. Proceedings of MT Summit XIX, 345-356.</li>
                        <li>Lin, H., et al. (2023). Intergenerational variation and AI model training. Computational Linguistics, 49(4), 678-702.</li>
                        <li>Sato, M., Chang, P., & Miyagawa, S. (2024). Bridging the digital divide in language revitalization. Language Documentation & Conservation, 18, 245-271.</li>
                        <li>Miyagawa, S., & Ito, A. (2025). Future directions for AI-assisted language revitalization. International Journal of the Sociology of Language, 271, 89-115.</li>
                        <li>Lin, H., et al. (2024). Evaluating AI tools for language learning outcomes. ReCALL, 36(2), 201-225.</li>
                        <li>Miyagawa, S., et al. (2025). Scaling AI-powered revitalization across Taiwan's indigenous languages. Anthropological Linguistics, 67(1), 56-84.</li>
                        <li>Sato, M., Miyagawa, S., Ito, A., & Chang, P. (2025). Ethical AI implementation in language revitalization. Ethics and Information Technology, 27(1), 1-22.</li>
                    </ol>
                    
                    <div class="citation">
                        Field-based Approaches to Language, Cognition, and Human Nature (FALCOHN)<br>
                        OS科研4 (2024-2027) - JSPS Kakenhi Grant-in-Aid (A)<br>
                        Led by Prof. Masatoshi Koizumi (Tohoku University)<br>
                        Research Team: So Miyagawa, Manami Sato, Akinori Ito, and fellow researchers working on Kaqchikel, Tongan, and Oki-no-Erabu languages
                    </div>
                </div>
            </div>
        </div>
    </div>

    <div class="navigation">
        <button class="nav-btn" id="prev-btn">← Previous</button>
        <div class="dots-container" id="dots-container"></div>
        <button class="nav-btn" id="next-btn">Next →</button>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const slides = document.querySelectorAll('.slide');
            const prevBtn = document.getElementById('prev-btn');
            const nextBtn = document.getElementById('next-btn');
            const progressBar = document.getElementById('progressBar');
            const dotsContainer = document.getElementById('dots-container');
            
            let currentSlideIndex = 0;
            const totalSlides = slides.length;
            
            // Create dot indicators
            for (let i = 0; i < totalSlides; i++) {
                const dot = document.createElement('div');
                dot.classList.add('dot');
                dot.setAttribute('data-index', i);
                dot.addEventListener('click', () => {
                    currentSlideIndex = i;
                    showCurrentSlide();
                });
                dotsContainer.appendChild(dot);
            }
            
            // Update slide numbers in headers
            slides.forEach((slide, index) => {
                const slideNumber = slide.querySelector('.slide-number');
                if (slideNumber) {
                    slideNumber.textContent = `${index + 1}/${totalSlides}`;
                }
            });
            
            // Update progress bar
            function updateProgressBar() {
                const progress = ((currentSlideIndex + 1) / totalSlides) * 100;
                progressBar.style.width = `${progress}%`;
            }
            
            // Update button states
            function updateButtonStates() {
                prevBtn.disabled = currentSlideIndex === 0;
                nextBtn.disabled = currentSlideIndex === slides.length - 1;
            }
            
            // Update dots
            function updateDots() {
                const dots = document.querySelectorAll('.dot');
                dots.forEach((dot, index) => {
                    if (index === currentSlideIndex) {
                        dot.classList.add('active');
                    } else {
                        dot.classList.remove('active');
                    }
                });
            }
            
            // Show current slide and hide others
            function showCurrentSlide() {
                slides.forEach((slide, index) => {
                    if (index === currentSlideIndex) {
                        slide.classList.add('active');
                        slide.classList.remove('prev');
                    } else if (index < currentSlideIndex) {
                        slide.classList.remove('active');
                        slide.classList.add('prev');
                    } else {
                        slide.classList.remove('active');
                        slide.classList.remove('prev');
                    }
                });
                
                updateProgressBar();
                updateButtonStates();
                updateDots();
            }
            
            // Move to previous slide
            prevBtn.addEventListener('click', function() {
                if (currentSlideIndex > 0) {
                    currentSlideIndex--;
                    showCurrentSlide();
                }
            });
            
            // Move to next slide
            nextBtn.addEventListener('click', function() {
                if (currentSlideIndex < slides.length - 1) {
                    currentSlideIndex++;
                    showCurrentSlide();
                }
            });
            
            // Keyboard navigation
            document.addEventListener('keydown', function(event) {
                if (event.key === 'ArrowLeft') {
                    if (currentSlideIndex > 0) {
                        currentSlideIndex--;
                        showCurrentSlide();
                    }
                } else if (event.key === 'ArrowRight') {
                    if (currentSlideIndex < slides.length - 1) {
                        currentSlideIndex++;
                        showCurrentSlide();
                    }
                }
            });
            
            // Initial setup
            updateButtonStates();
            updateProgressBar();
            updateDots();
        });
    </script>
</body>
</html>